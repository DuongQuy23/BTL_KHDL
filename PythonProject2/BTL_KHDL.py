import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

st.title("üìà D·ª± b√°o gi√° c·ªï phi·∫øu b·∫±ng LSTM")
st.write("T·∫£i l√™n m·ªôt file CSV ch·ª©a d·ªØ li·ªáu gi√° c·ªï phi·∫øu ƒë·ªÉ ph√¢n t√≠ch v√† d·ª± b√°o.")

uploaded_file = st.file_uploader("üì§ Vui l√≤ng t·∫£i l√™n file CSV c√≥ c·ªôt 'Date' v√† 'Close'.", type="csv")

def create_dataset(dataset, look_back=1):
    X, Y = [], []
    for i in range(len(dataset) - look_back):
        a = dataset[i:(i + look_back), 0]
        X.append(a)
        Y.append(dataset[i + look_back, 0])
    return np.array(X), np.array(Y)

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)

    # Ki·ªÉm tra c·ªôt c·∫ßn thi·∫øt
    if 'Date' not in df.columns or 'Close' not in df.columns:
        st.error("‚ùå File CSV ph·∫£i c√≥ c·ªôt 'Date' v√† 'Close'.")
    else:
        df['Date'] = pd.to_datetime(df['Date'])
        df = df.sort_values('Date')

        st.success("‚úÖ File h·ª£p l·ªá. Hi·ªÉn th·ªã d·ªØ li·ªáu g·∫ßn nh·∫•t:")
        st.dataframe(df.tail(10))

        # Chu·∫©n b·ªã d·ªØ li·ªáu cho LSTM
        data = df[['Close']].values.astype('float32')

        scaler = MinMaxScaler(feature_range=(0, 1))
        data_scaled = scaler.fit_transform(data)

        look_back = 10  # s·ªë b∆∞·ªõc th·ªùi gian d·ª±a v√†o ƒë·ªÉ d·ª± ƒëo√°n

        X, Y = create_dataset(data_scaled, look_back)

        # Chia t·∫≠p train/test: 80% train
        train_size = int(len(X) * 0.8)
        X_train, X_test = X[:train_size], X[train_size:]
        Y_train, Y_test = Y[:train_size], Y[train_size:]

        # Reshape input cho LSTM [samples, time steps, features]
        X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
        X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

        # X√¢y d·ª±ng m√¥ h√¨nh LSTM
        model = Sequential()
        model.add(LSTM(50, input_shape=(look_back, 1)))
        model.add(Dense(1))
        model.compile(loss='mean_squared_error', optimizer='adam')

        # Hu·∫•n luy·ªán m√¥ h√¨nh
        st.write("‚è≥ ƒêang hu·∫•n luy·ªán m√¥ h√¨nh LSTM...")
        model.fit(X_train, Y_train, epochs=20, batch_size=16, verbose=0)
        st.success("‚úÖ ƒê√£ hu·∫•n luy·ªán xong m√¥ h√¨nh!")

        # D·ª± b√°o
        train_predict = model.predict(X_train)
        test_predict = model.predict(X_test)

        # Chuy·ªÉn ng∆∞·ª£c v·ªÅ gi√° tr·ªã th·ª±c
        train_predict = scaler.inverse_transform(train_predict)
        Y_train_real = scaler.inverse_transform(Y_train.reshape(-1,1))
        test_predict = scaler.inverse_transform(test_predict)
        Y_test_real = scaler.inverse_transform(Y_test.reshape(-1,1))

        # V·∫Ω bi·ªÉu ƒë·ªì so s√°nh d·ª± b√°o
        st.subheader("Bi·ªÉu ƒë·ªì d·ª± b√°o gi√° c·ªï phi·∫øu")

        fig, ax = plt.subplots(figsize=(12,6))
        ax.plot(df['Date'][look_back:look_back+len(train_predict)], train_predict, label='D·ª± b√°o train')
        ax.plot(df['Date'][look_back+len(train_predict):look_back+len(train_predict)+len(test_predict)], test_predict, label='D·ª± b√°o test')
        ax.plot(df['Date'], df['Close'], label='Gi√° th·ª±c t·∫ø', color='black', alpha=0.6)
        ax.set_xlabel('Ng√†y')
        ax.set_ylabel('Gi√° ƒë√≥ng c·ª≠a')
        ax.legend()
        st.pyplot(fig)
else:
    st.info("üì• Vui l√≤ng t·∫£i l√™n file CSV ƒë·ªÉ b·∫Øt ƒë·∫ßu d·ª± b√°o.")
